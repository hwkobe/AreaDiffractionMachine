One of the most common types of analysis of diffraction data
is to perform an intensity integration in $Q$. This will 
create a plot of average intensity as a function of $Q$.
Since powder diffraction procedures cones of light, this means
that the intensity should be uniformly large for some $Q$
values and uniformly low for others, leading to $Q$ values
where the intensity sharply peaks. The $Q$ values that lead 
to these peaks can be used to learn structural information
about the crystals that are being diffracted. So in principle,
using the transformations just described, it should be easy
to convert all of the pixel coordinates $(x_d,y_d)$ into
$Q$ values and then plot average intensity as a function of
$Q$. The only problem we would face is that in order to do
the transformation, we would need to know the values of the
the parameters that characterize an experiment. These are
\index{$\alpha$}\index{$\beta$}\index{Rotation}
$x_c$, $y_c$, $d$, $\lambda$, $\alpha$, $\beta$, and 
$R$.\footnote{The pixel scale $ps$ is usually know in advance 
as a uniform property of the detector being used.} Calibration
then is the process used to find what we will now call the
calibration values.

\section{The Calibration Algorithm}\index{calibration}

Although in principle all the calibration values could be
experimentally measured, in practice they can not be
directly measured to an acceptable level of precision. 
Instead, a standard calibration procedure is used to 
infer these values from real diffraction data. The 
trick to doing this calibration is to image a standard
while performing the diffraction analysis of an 
unknown sample. Assuming that the diffraction machine
was not changed between the collection of the 
standard crystal and the diffraction of the unknown sample, 
the calibration data corresponding to the two 
images will be the same. So, if we can figure out the
calibration values of the standard crystal, we can
use these values when analyzing the unknown crystal.
This is exactly what is done in practice.

What it means to use a standard crystal is to know the
particular $Q$ values for which the crystal preferentially
scatters light. With this information, and the 
calibration values for some particular experiment,
we could in principle figure out exactly what diffraction
pattern we should find. This do this, we could, for
each $Q$ value, vary $\chi$ and calculate the 
$(x_d,y_d)$ coordinate corresponding to that $(Q,\chi)$
pair. After using enough $\chi$ values, we would be 
able to fill in the rings as they would show up on 
the detector.

In fact, my program can do just this. If you load in 
a set of $Q$ values (more about this in section 
\ref{TheQValues})\index{$Q$ Values}
and then put into the program some calibration values,
and then push the \gui{Draw Q Values?} check box, 
you can then see what the particular diffraction
image would have shown up on the detector. 
(NEED TO SHOW EXAMPLE HERE)

Being able to do this still leaves us with a hard 
problem to solve. For particular calibration values,
we can easily calculate what the diffraction pattern 
should look like. But what we really know is what
the calibration values are for the known diffraction
pattern of a standard crystal. In order to perform the
real calibration, then, we can vary the calibration 
values until they make the pattern that can be calculated
to show up to match the pattern that was actually 
captured. The process of image calibration then is a 
procedure to `fit' the calibration values to a
diffraction patter with known $Q$ values.

\section{The Fitting} 
\index{Fitting}
In order for the fitting algorithm to work, the program 
must already have an initial guess of the real calibration 
parameters. This initial guess does not have to be perfect, 
but it should be somewhat close. The algorithm them requires 
a list of the known $Q$ values. And it additionally requires 
a range for each of these $Q$ values. In order for the 
algorithm to work properly, inside of this $Q$ range (as 
calculated by the initial calibration value guess) there 
should be the peaks that we are interested in and no spurious 
other peaks that would confuse the computer.

With the $Q$ values specified along with $Q$ ranges, we can
divided up any diffraction image several regions, where
within each region we know there is a unique peak.
(SHOWN AN EXAMPLE HERE).

\begin{SCfigure}
\centering
\input{figures/Fitting.tex}
\caption{Here is a diagram of the peak finding 
algorithm. ADD MORE OF A CAPTION}
\label{fitting}
\end{SCfigure}

Our algorithm first requires\index{Peak Finding}
finding $(x,y)$ coordinates 
of many diffraction peaks. To do so, the algorithm will 
pick some $\chi$ value and then 
spread radially out from the center of the diffraction
image in this $\chi$ direction.\footnote{Remember
that the center is specified by the initial calibration 
values}. Between the given $Q$ range (for each of the $Q$ 
ranges), the program stores an array of all the data point 
on the line. It then fits a Gaussian to the data and the
$(x,y)$ coordinate of the center of this Gaussian $(x,y)$ 
is taken to be the peak. A diagram showing this algorithm
is shown in figure~\ref{fitting}. This method is
then done for many different evenly spaced $\chi$ values
and the particular value can be selected by the user
for increased accuracy.

The only really tricky part about this step is that
there is not always a consistent diffraction ring 
around the image and therefore some of these fits 
should not find peaks. Whenever this occurs, the program
just ignores the current fit and moves to the next. 
But figuring out when some particular peak is bad
is not particularly obvious. The method that this
program uses is to ensure each peak passes a few
tests. The first test is that the fit peak was
too close to the edge of the image. So any peak where
the Gaussian fit's center plus or minus twice the fit's
standard deviation gets outside of the $Q$ range is
considered too close to the edge of the image.
The next test that is done is to calculate is the
standard deviation of the data outside of the peak is
significant when compared to the height of the peak
fit. To do this, the code calculates the standard 
deviation of all the pixels that are farther then twice
the peak's fit standard deviation away from the
center of the peak. If the height of the peak
divided by this calculated background standard deviation
is smaller then some particular value, the peak is
considered bad. This value is called by the program
\gui{Stddev} and can be specified by the user from user.
\index{Stddev}
Presumably, the higher that \gui{Stddev} is, the
more picky the program is about what a good peak looks
like. This isn't the most robust method for finding peaks,
but it seems to work pretty well and it should be easy 
in principle to add new tests to the algorithm.

After compiling a list of diffraction peaks in the image,
the program can then define a residual function which
we can minimize to find the best fit calibration values.
To do so, we can convert the $(x,y)$ coordinate
of each of the peaks into a 
$(Q_{\text{peak}},\chi_{\text{peak}})$ pair. 
For each of these $(x,y)$ coordinates, we also
know what the input $Q$ list says the experimental $Q$ 
value for this peak should be (which we will call 
$Q_{\text{exp}}$). We can therefore define
the residual function as
\begin{equation}
    \text{Residual}(x_c,y_c,d,\lambda,\alpha,\beta,R) =  
    \sum_{\text{$x,y$ pairs}} (Q_{\text{peak}} - Q_{\text{exp}})^2
\end{equation}
Note that the functional dependence comes in from
calculating $Q_{\text{peak}}$ from a known
$(x,y)$ coordinate. We see that the smaller the 
Residual is, the closer we have come to finding 
the real calibration values which characterized
the diffraction experiment. If we had perfect
calibration parameters, the residual should be
equal to zero. But it is well defined for any
calibration parameters. So we can take this 
function of 7 variables and minimize it. 
The value of this function at its minimized 
is the best guess calibration values.
There are plenty of computer algorithm that
can minimize arbitrary multi-variable functions.
The one that this code uses is called the 
Levenberg-Marquardt\index{Least Squares Minimization}
nonlinear least squares algorithm
and the particular implementation that is used
to to perform the calibration is Manolis Lourakis's
levmar library\cite{lourakis04LM}. Ideallly, 
once the minimization is done, a good guess at the
calibration values is found.

\section{Calibrating With the Program}

\subsection{Displaying Peaks}

\subsection{Masking Peaks}

\section{Save the Peak List}

\section{\texorpdfstring{The $Q$ File Format}{The Q File Format}}
\label{TheQValues}\index{Q Data}
Below is a valid Q Data File:
\begin{lstlisting}[caption={Lanthanum Hexaboride.dat},label=LaB6]
# This is Q Data for Lanthanum Hexaboride
Q   dQ
1.511543809 .05
2.137646823 .05
2.618102966 .05
3.023087619 .05
3.379873753 .05
3.702525225 .05
4.275148198 .05
4.534631428 .05
4.77990514  .05
5.013313099 .05
5.23603139  .05
5.44989618  .05
\end{lstlisting}
Comment lines beginning with a \# are always ignored. The
first line in the file should be of the form "Q  dQ" or "Q  delta Q" 
to specify that this is a list of $Q$ values. The rest of the
file should have $Q$ values followed a $\Delta Q$ range.
All $Q$ values must be larger than 0. None of the $Q$ ranges can 
overlap. Instead of inputting $Q$ values, the program can input
$D$ values if the first line is instead "D dD" or "D delta D"
The values should be given instead in $D$ space and the values
will be converted using~\ref{DtermsQ}.


